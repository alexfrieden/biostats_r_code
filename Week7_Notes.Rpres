Week7 Notes
========================================================
author: Alexander Frieden 
date: 3/10/2016

Genetics Primer
========================================================

It has come to my attention that I need to go over some of the genetics we are doing


SNP
==========================================

Single nucleotide polymorphism

This is the result of a single basepair being swapped for a different one.  

![snp](pictures/snp.jpeg)

Indel
=========================================

* This is any insertion deletion or any multi-basepair substitution (which is really a deletion or insertion). 

* Theoretically a structural variation such as the deletion of an entire gene can be thought of as an indel

* Practically, we keep them seperate.  This is usually due to the nature of how computational algorithms call small indels vs how they call structural variations.  

Gene vs Genome
=========================================

* The gene is one of the larger strucutres of cell biology and is the key of which we map proteins that are coded from them onto.  

* The genome is the union of all genes plus the sections between the genes.  

Reads
========================================
Multiple, fragmented sequence reads must be assembled together on the basis of their overlapping areas.

Variants are then called from this person.  


Reads (continued)
========================================
![reads](pictures/reads.png)



Classification
========================================

Sometimes we don't want to predict a value i.e. how much money will I have in a year but I want to estimate a qualitative value.  

This is called classifing a valitative response or **classification**.  

Examples
========================================

* A person arrives at the emergency room with a set of symptoms that could possibly be attributed to one of three medical conditions.  Which of the three conditions does the individual have?

* An online banking service must be able to determine whether or not a transaction being performing on the site is fraudulent, on the basis of a user's IP address, past transaction history, and other features.

* On the basis of DNA variation data for a number of patients with and without a given disease, we would like to discern which variants are deleterious (disease causing) and which are not.

Note
========================================

For the computer scientists in the room, a lot of this will sound very similar to machine learning, and that is because it is.  

Instead of finding a pattern or threshold, we are finding things that fall enough outside of our distribution that they qualify for or against a classification (such as GOOD or BAD) and we can process them as such.  


Training
========================================

Just like in regression, we have a set of training observations

$$
(x_1,y_1),(x_2,y_2),...,(x_n,y_n)
$$

that we can use to build a classifier.

Training Data
========================================

We want our classifier to perform well on our training data but also on our test data.  

As a matter of practice, you *never* use the same training set as your test set.  This creates a false sense of security in your classifier and you won't be accurately testing your data.  


Default data set
==========================================

For this we will use the **default** dataset

```{r}
install.packages("ISLR",repos="http://cran.rstudio.com/")
library(ISLR)
```


Default data set (part 2)
==========================================
```{r}
head(Default)
```


Plot difference
===========================

```{r}
default.yes <- subset(Default,default=="Yes")
default.no <- subset(Default,default=="No")
plot(default.yes$balance,default.yes$income, col="blue")
points(default.no$balance,default.no$income,col="red")
```

More clearly
===============================

![](pictures/gareth_4.1a.pdf)


Description of Default Data Set
===============================

This dataset describes the annual incomes and monthly credit card balances of a number of individuals.   

The individuals who defaulted on thei credit card payments are shown in orange and those who did not are shown in blue.  

Linear Regression Classifiers (part 1)
===============================

In cases where you have a qualitative classification, you can't use linear regression

Suppose we are trying to predict the medical condition of a patient in the emergency room on the basis of symptoms.  

We have three possible diagnoses: **stroke, drug overdose, and epileptic seizure**.  We encode them in response variable $Y$

$$
Y = \left\{
        \begin{array}{ll}
            1 & if\,stroke \\
            2 & if\,drug\,overdose \\
            3 & if\,epileptic\,seizure
        \end{array}
    \right.
$$


Linear Regression Classifiers (part 2)
===============================

Using this coding, we could use least squares to fit a linear regression model.  

From this we would get a set of predictors $X_1,...,X_n$.  

What is our incorrect assumption with this?

Linear Regression Classifiers (part 3)
===============================

The issue is we assume this map actually means something, but it doesn't.  The values we pick are arbitrary.  

Our model would assume the difference between **stroke** and **drug overdose** is not the same as **stroke** to **epileptic seizure** which may or may not be true.  

We could just have easily picked:

$$
Y^{\prime} = \left\{
        \begin{array}{ll}
            1 & if\,epileptic\,seizure \\
            2 & if\,stroke \\
            3 & if\,drug\,overdose
        \end{array}
    \right.
$$

Linear Regression Classifiers (part 3)
===============================

This new mapping would give a completely different set of the relationships and values.  

If we had something like **mild, moderate, and severe** then some values associated with them and an ordering would have been reasonable.  

That is not the case here. 

Linear Regression Classifiers (part 4)
===============================

We want to look at doing this with binary mapping, but for that we first need to understand **dummy variable** approach.

Dummy Variable Approach
===============================

* Suppose we wish to investigate difference in credit card balance between males and females.  

* We can simply create an indicator or *dummy variable*

$$
x_i = \left\{
        \begin{array}{ll}
            0 & if\,ith\,person\,is\,female \\
            1 & if\,ith\,person\,is\,male \\
        \end{array}
    \right.
$$

Dummy Variable Approach
===============================

If we did this and used $x_i$ as the predictor in linear regression then we would get the following model.

$$
y_i = \beta_0 + \beta_{1}x_i + \epsilon_i =  \\
\left\{
        \begin{array}{ll}
            \beta_0 + \beta_1 + \epsilon_i & if\,i^{th}\,person\,is\,female \\
            \beta_0 + \epsilon_i & if\,i^{th}\,person\,is\,male \\
        \end{array}
    \right.
$$

Interpretation
===============================

Now $\beta_0$ can be interpreted as the average credit card balance among males and $\beta_0 + \beta_1$  as the average credit card balance among females.  

When this actually gets computed on the **Credit** data set, you do get a very high p value, showing little statistical evidence of a difference in average credit balance between genders.

This same pattern can be done on systems of more than two levels.  

Back to example
===============================

so lets implement the dummy variable approach.

$$
Y = \left\{
        \begin{array}{ll}
            0 & if\,stroke \\
            1 & if\,drug\,overdose
        \end{array}
    \right.
$$

Doing this allows us to predict drug overdose if $\hat{Y} > 0.5$ and stroke overwise.  

The linear regression gives us a rough estimate of probability as some of the values are negative. 

Note
===============================

Its tough to extend the qualitative responses using linear regression for more than 2 levels.  

For this reason we try to avoid it. 

Logistic Regression
===============================

Consider the **Default** dataset where we annotate whether someone defaults with **Yes** or **No**.  Logistic regression models the *probability* that Y belongs to a particular category.  

Logistic Regression part 2
===============================


```{r fig.width=100, fig.height=100,echo=FALSE}
install.packages("png", repos="http://cran.rstudio.com/")
library(png)
library(grid)
img <- readPNG("pictures/gareth_figure_4.2.png")
 grid.raster(img)
```

Logistic Regression part 3
===============================

For the Default data set, logistic regression models the probability of default.  

For example: the probability of default given balance can be written as:

$$
P(default=Yes\,|\,balance)
$$

We might predict **default = yes** if the probability is greater than $0.5$.  We also might be more conservative and use $0.1$

R Regression Example part 1
========================================

We are going to examine stock market data from the S&P 500 from 2001 to 2005.  

For each date we have recorded the percentage of returns for each of the five previous trading days Lag1 through Lag5 and the **Volume* (number of billions of shares traded previous day).

**Today** is the percentage return on the date in question

**Direction** whether they market was up or down on the date

R Regression Example part 2
========================================

load our library and take a look at our data.

```{r}
library(ISLR)
names(Smarket)
```

R Regression Example part 3
========================================

Summary of our data to get a sense of data.  
```{r}
summary(Smarket)
```

R Regression Example part 4
========================================

Next we might want to look for a naive pearson correlation between pairwise correlations among the predictors in a data set.  

```{r}
#cor(Smarket)
```
We get the error:
Error in cor(Smarket) : 'x' must be numeric


R Regression Example part 5
========================================

What happened?  Well it broke because the values are qualitative

```{r}
head(Smarket)
```

R Regression Example part 6
========================================

We can fix this by subsetting our data.

```{r}
head(Smarket[,-9])
```

R Regression Example part 7
========================================

Now lets look at the correlation

```{r}
cor(Smarket[,-9])
```

R Regression Example part 8
========================================

Unfortunately we don't get anything quite this fast, we need to do further investigation.  


Notes on Pearson Correlation
=========================================

![its a lie!](pictures/3030529-slide-wufrozj.png)

Notes on Pearson Correlation (part 2)
=========================================

Obviously correlation does not imply causation.  

Notes on Pearson Correlation (part 3)
=========================================

![its a lie!](pictures/Correlation_examples.png)


Logistic Regression in R part 1
=========================================

Next we want to fit logistic regression model to predict **Direction** using **Lag1** through **Lag5** and volume.  
Logistic Regression in R part 2
=========================================

The **glm()** method functions a lot like **lm()** except tht we must pass in the argument **family=binomial** in order to tell R to run a logistic representation rather than some other type of generalized linear model.

Logistic Regression in R part 3
=========================================

```{r}
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
            data=Smarket,family=binomial)
```

Logistic Regression in R part 4
=========================================
```{r}
summary(glm.fit)
cat('\r\n\r\n')
```

Logistic Regression in R part 5
=========================================
The smallest p-value here is associated with **Lag1**.  

The negative coefficient for this predictor suggests that if the market had a positive return yesterday, then it less likely to go up today.  

Note:  the value is 0.15, the p-value is relatively high and so there is no CLEAR evidence of a real association between **Lag1** and **Direction**

Predicting 
=========================================

The **predict()** function can be used to predict the probability that the market will go up, given values of the predictors.  

The **type=response** option tells R to output probabilities of the form $P(Y=1|X)$.  

If no data set is provided **predict()** will then compute probabilies for the training datat that was used to fit the logistic regression model.  Why is this bad?

Predicting (part 2)
=========================================
In, the following, we have only pritned the first ten probabilities.  

We know the values correspond to the probability of the market going u rather than down because the **contrasts()** function indicates that R has created a dummy variable with a 1 for **Up**

Predicting (part 3)
=========================================

```{r}
attach(Smarket)
glm.probs=predict(glm.fit,type="response")
glm.probs[1:10]
contrasts(Direction)
```



Predicting (part 4)
=========================================

In order to make an actual prediction we need to convert the predictions to proper labels.  

```{r}
glm.pred=rep("Down",1250)
glm.pred[glm.probs > 0.5]="Up"
```

Predicting (part 5)
=========================================

So this command first creates a vector of 1250 Down elements.  

The second line transforms to **Up** all the elements for which the predicted probability of a market increase exceeds 0.5.  

We can now use a tool known as a *confusion matrix* to see how good this prediction is

Predicting (part 6)
=========================================
```{r}
table(glm.pred, Direction)
(507+145)/1250
mean(glm.pred==Direction)
```

Predicting (part 7)
=========================================
The diagonal elements of the confusion matrix indicate correct predictions, off-diagonals are the incorrect ones.  

Our model did 652 correct predictions which correctly predicted the market 52.2% of the time.

The **mean()** function was used to compute the fraction of days for which the prediction was correct.  

Predicting (part 8)
=========================================

It appears logistic regression model did well.  

However result is misleading because we traomed amd tested the model on same set of 1250 observations.  

In other words $100 - 52.2 = 47.8%$ is the training error rate.  

Predicting (part 9)
=========================================

The training error rate is an overestimate of the test error rate.  

Our best bet here is to use part of the data to train the model then use the remaining data to test it, such that the data sets are disjoint.  

This will give us a more realistic error rate.

Predicting (part 10)
=========================================

First we need to subset our data.  We do this by creating a vector corresponding to observations from 2001 to 2004.  

```{r subset_market_data}
train=(Year<2005)
Smarket.2005 = Smarket[!train,]
dim(Smarket.2005)
Direction.2005=Direction[!train]
```

Predicting (part 11)
=========================================

Now we fit a logistic regression model using the subset observations that correspond to dates before 2005.

We then get predicted probabilities for the market for days in 2005.

Predicting (part 12)
=========================================

```{r}
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
            data=Smarket, family=binomial, subset=train)
glm.probs=predict(glm.fit, Smarket.2005,type="response")
```

Predicting (part 13)
=========================================
Notice we have trained and teted our model on two disjoint data sets: 2001-2005 and 2005

Now we compare to actual values.  

Predicting (part 14)
=========================================
```{r compare}
glm.pred=rep("Down",252)
glm.pred[glm.probs>0.5]="Up"
table(glm.pred,Direction.2005)
mean(glm.pred==Direction.2005)
mean(glm.pred!=Direction.2005)
```

Predicting (part 15)
=========================================

Sadly, results show we get 52% test error rate.

Predicting (part 16)
=========================================

Remember initially our smallest p-value for our model was very large which belonged to **Lag1**

We can try to remove the other variables to get a better model.  

This is due to when we use predictors that haveno relationship with the response tends to cause a deterioration in the test error rate by causing an increaes in the variance but no decrease in bias.  

the bias of an estimator is the difference between this estimator's expected value and the true value of the parameter being estimated

Predicting (part 17)
=========================================

Lets try using just **Lag1** and **Lag2**

```{r}
glm.fit=glm(Direction~Lag1+Lag2,data=Smarket,family=binomial,subset=train)
glm.probs=predict(glm.fit,Smarket.2005,type="response")
glm.pred=rep("Down",252)
glm.pred[glm.probs>0.5] = "Up"
table(glm.pred,Direction.2005)
```

Predicting (part 18)
=========================================
